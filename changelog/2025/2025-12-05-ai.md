---
icon: sparkles
layout:
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: false
  pagination:
    visible: true
---

# 2025-12-05: AI Service - support for VLLM provider

## Overview

Extended existing API for Agents by adding LLM provider of `self_hosted_vllm` type which supports self deployed VLLM.

## Updated endpoints

| Endpoint                                                                                                                                                                                 | Description                                        |
|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------|
| [Listing agents](https://developer.emporix.io/api-references/api-guides/artificial-intelligence/ai-service/api-reference/agent#get-ai-service-tenant-agentic-agents)                     | New LLM provider is supported: `self_hosted_vllm`. |
| [Searching agents](https://developer.emporix.io/api-references/api-guides/artificial-intelligence/ai-service/api-reference/agent#post-ai-service-tenant-agentic-agents-search)           | New LLM provider is supported: `self_hosted_vllm`. |
| [Retrieving agent by ID](https://developer.emporix.io/api-references/api-guides/artificial-intelligence/ai-service/api-reference/agent#get-ai-service-tenant-agentic-agents-agentid)     | New LLM provider is supported: `self_hosted_vllm`. |
| [Upserting agent](https://developer.emporix.io/api-references/api-guides/artificial-intelligence/ai-service/api-reference/agent#put-ai-service-tenant-agentic-agents-agentid)            | New LLM provider is supported: `self_hosted_vllm`. |
| [Partially updating agent](https://developer.emporix.io/api-references/api-guides/artificial-intelligence/ai-service/api-reference/agent#patch-ai-service-tenant-agentic-agents-agentid) | New LLM provider is supported: `self_hosted_vllm`. |

## Known problems

There are no known problems.

